#!/bin/bash
# æµå¼æ¼”ç¤ºè„šæœ¬ (æ”¯æŒ VAD åˆ†æ®µæ¨¡å¼)
# ä½¿ç”¨ VAD è¿›è¡Œè¯­éŸ³åˆ†æ®µï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§
#
# ç”¨æ³•: bash demo_streaming.sh [sample] [process_seconds] [sv_threshold] [--vad] [--debug]
# ç¤ºä¾‹: 
#   bash demo_streaming.sh s1              # ä½¿ç”¨s1æ ·æœ¬ï¼Œå›ºå®šé—´éš”æ¨¡å¼
#   bash demo_streaming.sh s1 2.0 0.4 --vad  # ä½¿ç”¨ VAD åˆ†æ®µæ¨¡å¼
#   bash demo_streaming.sh s1 3.0 0.3 --debug  # å¯ç”¨è°ƒè¯•æ¨¡å¼

set -e

SCRIPT_DIR=$(cd "$(dirname "$0")" && pwd)
cd "$SCRIPT_DIR"

# æ ·æœ¬é€‰æ‹© (s1-s10)
SAMPLE=${1:-s1}
# æµå¼å¤„ç†é—´éš”ç§’æ•°ï¼ˆä»…å›ºå®šé—´éš”æ¨¡å¼ä½¿ç”¨ï¼‰
PROCESS_SECONDS=${2:-3.0}
# SV é˜ˆå€¼ (0-1ï¼Œè¶Šä½Žè¶Šå®¹æ˜“åŒ¹é…)
SV_THRESHOLD=${3:-0.4}

# æ£€æŸ¥é¢å¤–å‚æ•°
USE_VAD=""
DEBUG_MODE=""
for arg in "$@"; do
    if [ "$arg" == "--vad" ]; then
        USE_VAD="yes"
    fi
    if [ "$arg" == "--debug" ]; then
        DEBUG_MODE="--debug"
    fi
done

PROJECT_DIR=$(dirname "$SCRIPT_DIR")

# èŽ·å–ç›®æ ‡è¯´è¯äººæ–‡ä»¶ï¼ˆç¬¬ä¸€ä¸ªéžmix.wavçš„wavæ–‡ä»¶ï¼‰
TARGET_WAV=$(ls "${PROJECT_DIR}/dataset/cn/${SAMPLE}/"*.wav | grep -v mix.wav | head -1)

echo "=================================================="
echo "  ðŸŽ¤ æµå¼å£°çº¹è¯†åˆ«æ¼”ç¤º"
if [ -n "$USE_VAD" ]; then
    echo "  ðŸ“Š VAD åˆ†æ®µæ¨¡å¼ - åŸºäºŽè¯­éŸ³è¾¹ç•Œåˆ†æ®µ"
else
    echo "  ðŸ“Š å›ºå®šé—´éš”æ¨¡å¼ - ${PROCESS_SECONDS}ç§’é—´éš”"
fi
echo "  æ ·æœ¬: $SAMPLE"
echo "  SVé˜ˆå€¼: ${SV_THRESHOLD}"
echo "  ç›®æ ‡: $(basename "$TARGET_WAV")"
echo "=================================================="
echo ""

# æž„å»º VAD å‚æ•°
VAD_ARGS=""
if [ -n "$USE_VAD" ]; then
    VAD_ARGS="--vad-model ${PROJECT_DIR}/models/vad/silero_vad.onnx"
fi

python demo_streaming.py \
    --mix-wav "${PROJECT_DIR}/dataset/cn/${SAMPLE}/mix.wav" \
    --target-wav "${TARGET_WAV}" \
    --spk-embed-model "${PROJECT_DIR}/models/speaker-recognition/3dspeaker_speech_eres2net_base_sv_zh-cn_3dspeaker_16k.onnx" \
    --sense-voice "${PROJECT_DIR}/models/asr/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx" \
    --tokens "${PROJECT_DIR}/models/asr/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt" \
    --provider cuda \
    --sv-threshold "$SV_THRESHOLD" \
    --chunk-size 1024 \
    --process-seconds "$PROCESS_SECONDS" \
    $VAD_ARGS \
    $DEBUG_MODE 2>&1 | grep -v "Warning\|FutureWarning\|UserWarning\|pytorch_lightning\|TensorFloat\|weights_only\|Model was trained\|Lightning automatically\|Using HF token"
