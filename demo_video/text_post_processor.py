#!/usr/bin/env python3
"""
æ–‡æœ¬åå¤„ç†å™¨ - æ¸…ç†å’Œæ”¹è¿›è¯†åˆ«ç»“æœ
"""
import re
from typing import List, Dict
from difflib import SequenceMatcher


class TextPostProcessor:
    """åå¤„ç†è¯†åˆ«æ–‡æœ¬çš„å·¥å…·ç±»"""

    def __init__(self, target_text: str = ""):
        """
        åˆå§‹åŒ–å¤„ç†å™¨

        Args:
            target_text: ç›®æ ‡å‚è€ƒæ–‡æœ¬ï¼Œç”¨äºå¯¹é½å’Œçº æ­£
        """
        self.target_text = target_text
        self.target_text_no_punct = self._remove_punctuation(target_text)

    @staticmethod
    def _remove_punctuation(text: str) -> str:
        """ç§»é™¤ä¸­æ–‡æ ‡ç‚¹ç¬¦å·"""
        chinese_puncts = r"[ã€‚ï¼Œã€ï¼›ï¼šï¼Ÿï¼ï¼ˆï¼‰ã€Šã€‹" "''ã€ã€‘â€¦â€”ï½Â·]"
        return re.sub(chinese_puncts, "", text)

    def merge_segments(self, results: List[Dict]) -> str:
        """
        åˆå¹¶è¯†åˆ«æ®µè½ï¼Œå»é‡å’Œä¿®å¤

        Args:
            results: è¯†åˆ«ç»“æœåˆ—è¡¨

        Returns:
            åˆå¹¶åçš„æ–‡æœ¬
        """
        if not results:
            return ""

        # æå–æ–‡æœ¬å¹¶æ’åº
        sorted_results = sorted(
            results, key=lambda r: (r.get("seq_id", 0), r.get("start", 0))
        )
        texts = [r.get("text", "") for r in sorted_results]

        # åˆå¹¶å‰æ¸…ç†
        texts = [self._remove_punctuation(t) for t in texts]

        # å»é™¤ç©ºç™½æ–‡æœ¬
        texts = [t for t in texts if t.strip()]

        # å»é‡ç›¸é‚»é‡å¤
        merged = []
        for text in texts:
            if merged and merged[-1] == text:
                continue  # è·³è¿‡å®Œå…¨é‡å¤çš„ç›¸é‚»æ®µ
            merged.append(text)

        # å°è¯•ä¸ç›®æ ‡æ–‡æœ¬å¯¹é½ï¼Œçº æ­£æ˜æ˜¾é”™è¯¯
        merged = self._align_with_target(merged)

        return "".join(merged)

    def _align_with_target(self, texts: List[str]) -> List[str]:
        """
        å°è¯•ä¸ç›®æ ‡æ–‡æœ¬å¯¹é½ï¼Œçº æ­£æ‹¼å†™é”™è¯¯

        Args:
            texts: åˆ†æ®µæ–‡æœ¬åˆ—è¡¨

        Returns:
            ä¿®æ­£åçš„æ–‡æœ¬åˆ—è¡¨
        """
        if not self.target_text_no_punct:
            return texts

        # ç®€å•å¯å‘å¼å¯¹é½ï¼šçœ‹targetä¸­æ˜¯å¦åŒ…å«è¯¥æ–‡æœ¬çš„éƒ¨åˆ†
        result = []
        current_pos = 0

        for text in texts:
            # æŸ¥æ‰¾æœ€æ¥è¿‘çš„åŒ¹é…
            best_match = None
            best_score = 0.5  # æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼

            for start in range(
                max(0, current_pos - 5),
                min(len(self.target_text_no_punct), current_pos + 20),
            ):
                for end in range(start + len(text) - 2, start + len(text) + 3):
                    if start >= 0 and end <= len(self.target_text_no_punct):
                        target_substr = self.target_text_no_punct[start:end]
                        ratio = SequenceMatcher(None, text, target_substr).ratio()
                        if ratio > best_score:
                            best_score = ratio
                            best_match = target_substr
                            current_pos = end

            # å¦‚æœæ‰¾åˆ°ç›¸ä¼¼çš„ç›®æ ‡æ–‡æœ¬ç‰‡æ®µï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™ä¿æŒåŸæ–‡
            if best_match and best_score > 0.6:
                result.append(best_match)
            else:
                result.append(text)

        return result

    def get_statistics(self, results: List[Dict]) -> Dict:
        """
        è·å–è¯†åˆ«ç»Ÿè®¡ä¿¡æ¯

        Args:
            results: è¯†åˆ«ç»“æœåˆ—è¡¨

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not results:
            return {}

        sv_scores = [r.get("sv_score", 0) for r in results if r.get("sv_score")]
        kinds = {}
        for r in results:
            k = r.get("kind", "unknown")
            kinds[k] = kinds.get(k, 0) + 1

        return {
            "total_segments": len(results),
            "avg_sv_score": sum(sv_scores) / len(sv_scores) if sv_scores else 0,
            "max_sv_score": max(sv_scores) if sv_scores else 0,
            "min_sv_score": min(sv_scores) if sv_scores else 0,
            "kind_distribution": kinds,
        }

    def print_comparison(self, merged_text: str) -> None:
        """
        æ‰“å°ç›®æ ‡æ–‡æœ¬å’Œè¯†åˆ«æ–‡æœ¬çš„å¯¹æ¯”

        Args:
            merged_text: è¯†åˆ«åˆå¹¶åçš„æ–‡æœ¬
        """
        print("â•”" + "â•" * 68 + "â•—")
        print("â•‘                  ğŸ“Š æ–‡æœ¬å¯¹æ¯”åˆ†æ                             â•‘")
        print("â•š" + "â•" * 68 + "â•")
        print()

        print("ğŸ¯ ç›®æ ‡æ–‡æœ¬:")
        print(f"  {self.target_text}")
        print()

        print("ğŸ” è¯†åˆ«æ–‡æœ¬:")
        print(f"  {merged_text}")
        print()

        # è®¡ç®—ç›¸ä¼¼åº¦
        target_clean = self._remove_punctuation(self.target_text)
        ratio = SequenceMatcher(None, target_clean, merged_text).ratio()
        print(f"ğŸ“ˆ ç›¸ä¼¼åº¦: {ratio*100:.1f}%")
        print()


if __name__ == "__main__":
    # æµ‹è¯•ç¤ºä¾‹
    target = "è‹åŒ—å†›çš„ä¸€äº›çˆ±å›½å°†å£«é©¬å å±±ã€ææœã€å”å·¨æ­¦ã€è‹ç‚³çˆ±ã€é‚“é“æ¢…ç­‰ä¹Ÿå¥‹èµ·æŠ—æˆ˜ã€‚"
    processor = TextPostProcessor(target)

    # æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ
    results = [
        {"seq_id": 1, "start": 3.97, "text": "è‹åŒ—å†›çš„ä¸€äº›çˆ±å›½ã€‚"},
        {"seq_id": 2, "start": 5.95, "text": "å°†å£«é©¬å å±±ã€‚"},
        {"seq_id": 3, "start": 5.95, "text": "æœå”å·¨æ­¦ã€‚"},
        {"seq_id": 4, "start": 7.94, "text": "æœ±ç‚³çˆ±ã€é‚“é“æ¢…ç­‰ã€‚"},
        {"seq_id": 5, "start": 9.62, "text": "å¹¶ä¸”æŠ—æˆ˜ã€‚"},
        {"seq_id": 6, "start": 9.62, "text": "ä¹Ÿå¥‹èµ·ã€‚"},
    ]

    merged = processor.merge_segments(results)
    stats = processor.get_statistics(results)

    print("åˆå¹¶ç»“æœ:", merged)
    print("ç»Ÿè®¡ä¿¡æ¯:", stats)
    processor.print_comparison(merged)
