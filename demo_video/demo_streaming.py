#!/usr/bin/env python3
"""
æµå¼æ¼”ç¤ºè„šæœ¬ - æ¨¡æ‹Ÿå®æ—¶éº¦å…‹é£è¾“å…¥
ä» WAV æ–‡ä»¶è¯»å–éŸ³é¢‘ï¼ŒæŒ‰æµå¼æ–¹å¼é€å—å¤„ç†ï¼Œå±•ç¤ºå®æ—¶è¯†åˆ«æ•ˆæœ
"""
import sys
import time
from pathlib import Path

# æ·»åŠ è·¯å¾„
SCRIPT_DIR = Path(__file__).parent.parent
OSD_DIR = SCRIPT_DIR / "scripts" / "osd"
SRC_DIR = SCRIPT_DIR / "src"
for p in [str(OSD_DIR), str(SRC_DIR)]:
    if p not in sys.path:
        sys.path.insert(0, p)

import argparse
import numpy as np
import torchaudio
import torch
import threading
import unicodedata
from queue import Queue, Empty


def get_display_width(s):
    """è®¡ç®—å­—ç¬¦ä¸²çš„æ˜¾ç¤ºå®½åº¦ï¼ˆä¸­æ–‡å­—ç¬¦å 2ä¸ªå®½åº¦ï¼‰"""
    width = 0
    for char in s:
        if unicodedata.east_asian_width(char) in ("F", "W", "A"):
            width += 2
        else:
            width += 1
    return width


def pad_to_width(s, target_width):
    """å°†å­—ç¬¦ä¸²å¡«å……åˆ°æŒ‡å®šæ˜¾ç¤ºå®½åº¦"""
    current_width = get_display_width(s)
    padding = target_width - current_width
    if padding > 0:
        return s + " " * padding
    return s


def print_box(title, content_lines, style="single"):
    """æ‰“å°å¸¦è¾¹æ¡†çš„ä¿¡æ¯æ¡†"""
    width = 68
    if style == "double":
        top = "â•”" + "â•" * width + "â•—"
        bottom = "â•š" + "â•" * width + "â•"
        side = "â•‘"
    else:
        top = "â”Œ" + "â”€" * width + "â”"
        bottom = "â””" + "â”€" * width + "â”˜"
        side = "â”‚"

    print(top)
    if title:
        print(f"{side} {pad_to_width(title, width - 2)} {side}")
        print("â”œ" + "â”€" * width + "â”¤")
    for line in content_lines:
        print(f"{side} {pad_to_width(line, width - 2)} {side}")
    print(bottom)


def print_realtime_result(result, simulated_time):
    """æ‰“å°å®æ—¶è¯†åˆ«ç»“æœ"""
    kind = result.get("kind", "unknown")
    sv_score = result.get("sv_score", 0)
    text = result.get("text", "")
    stream_id = result.get("stream", "?")
    duration = result.get("duration", 0)

    # å›¾æ ‡å’Œç±»å‹æ ‡è¯†
    if kind == "vad_separated":
        icon = "ğŸ¤"
        kind_str = f"VAD#{stream_id}"
        color = "\033[96m"  # é’è‰²
    elif kind == "separated":
        icon = "ğŸ”Š"
        kind_str = f"åˆ†ç¦»#{stream_id}"
        color = "\033[94m"  # è“è‰²
    elif kind == "clean":
        icon = "âœ“"
        kind_str = "æ— é‡å "
        color = "\033[92m"  # ç»¿è‰²
    elif kind == "overlap":
        icon = "âš¡"
        kind_str = "OSDæ£€æµ‹"
        color = "\033[93m"  # é»„è‰²
    elif kind == "full_separation":
        icon = "ğŸ”„"
        kind_str = "å…¨åˆ†ç¦»"
        color = "\033[94m"  # è“è‰²
    else:
        icon = "â€¢"
        kind_str = kind
        color = "\033[0m"

    # SVåˆ†æ•°æŒ‡ç¤º
    if sv_score >= 0.8:
        sv_indicator = "ğŸŸ¢"
    elif sv_score >= 0.6:
        sv_indicator = "ğŸŸ¡"
    else:
        sv_indicator = "ğŸ”´"

    reset = "\033[0m"
    text_display = text[:50] + "..." if len(text) > 50 else text

    print(
        f"  [{simulated_time:>6.2f}s] {icon} {color}[{kind_str:^8}]{reset} {sv_indicator} SV={sv_score:.3f}"
    )
    print(f"            ğŸ“ {text_display}")


def create_progress_bar(current, total, width=40):
    """åˆ›å»ºè¿›åº¦æ¡"""
    progress = current / total
    filled = int(width * progress)
    bar = "â–ˆ" * filled + "â–‘" * (width - filled)
    return f"[{bar}] {progress*100:>5.1f}%"


class StreamingSimulator:
    """æµå¼å¤„ç†æ¨¡æ‹Ÿå™¨ - ä»WAVæ–‡ä»¶æ¨¡æ‹Ÿå®æ—¶æµå¼è¾“å…¥"""

    def __init__(
        self, pipeline, audio_data, sample_rate, chunk_size=1024, process_seconds=2.0
    ):
        self.pipeline = pipeline
        self.audio_data = audio_data
        self.sample_rate = sample_rate
        self.chunk_size = chunk_size
        self.process_seconds = process_seconds

        # è®¡ç®—å‚æ•°
        self.total_samples = len(audio_data)
        self.total_duration = self.total_samples / sample_rate
        self.frames_per_process = int(sample_rate * process_seconds / chunk_size)

        # çŠ¶æ€
        self.current_position = 0
        self.simulated_time = 0.0
        self.results = []
        self.running = False

    def run(self, realtime_display=True):
        """è¿è¡Œæµå¼æ¨¡æ‹Ÿå¤„ç†"""
        self.running = True
        audio_buffer = []
        chunk_count = 0

        print()
        print("â•”" + "â•" * 68 + "â•—")
        print("â•‘                    ğŸ™ï¸ æµå¼å¤„ç†ä¸­...                              â•‘")
        print("â•š" + "â•" * 68 + "â•")
        print()

        process_start = time.time()
        last_display_count = 0

        while self.current_position < self.total_samples and self.running:
            # è¯»å–ä¸€ä¸ª chunk
            end_pos = min(self.current_position + self.chunk_size, self.total_samples)
            audio_chunk = self.audio_data[self.current_position : end_pos]
            self.current_position = end_pos

            audio_buffer.append(audio_chunk)
            chunk_count += 1

            # æ›´æ–°æ¨¡æ‹Ÿæ—¶é—´
            self.simulated_time = self.current_position / self.sample_rate

            # ç´¯ç§¯å¤Ÿ process_seconds åå¤„ç†
            if len(audio_buffer) >= self.frames_per_process:
                combined_audio = np.concatenate(audio_buffer)

                # æ˜¾ç¤ºè¿›åº¦
                progress_bar = create_progress_bar(
                    self.current_position, self.total_samples
                )
                print(f"  â³ å¤„ç†åˆ†å— [{self.simulated_time:.1f}s] {progress_bar}")

                # å‘é€åˆ° pipeline
                self.pipeline.add_audio_data(combined_audio)
                audio_buffer = []

                # ç­‰å¾…å¤„ç†å®Œæˆ
                time.sleep(0.3)

                # è·å–å¹¶æ˜¾ç¤ºç»“æœ
                if realtime_display:
                    new_count = self._display_new_results()
                    if new_count > 0:
                        print()  # ç»“æœåç©ºè¡Œ

        # å¤„ç†å‰©ä½™æ•°æ®
        if audio_buffer:
            combined_audio = np.concatenate(audio_buffer)
            print(f"  â³ å¤„ç†æœ€ååˆ†å— [{self.simulated_time:.1f}s]")
            self.pipeline.add_audio_data(combined_audio)

        print()
        print("  âœ… éŸ³é¢‘å¤„ç†å®Œæˆï¼ç­‰å¾…è¯†åˆ«ç»“æœ...")

        # ç­‰å¾…æ‰€æœ‰å¼‚æ­¥å¤„ç†å®Œæˆ
        time.sleep(1.0)

        # æ”¶é›†å¹¶æ˜¾ç¤ºæ‰€æœ‰å‰©ä½™ç»“æœ
        final_count = (
            self._collect_and_display_results()
            if realtime_display
            else self._collect_all_results()
        )
        if final_count > 0:
            print(f"  ğŸ“¥ å…±æ”¶åˆ° {final_count} ä¸ªå»¶è¿Ÿç»“æœ")

        process_time = time.time() - process_start
        return process_time

    def _display_new_results(self):
        """æ˜¾ç¤ºæ–°çš„è¯†åˆ«ç»“æœï¼Œè¿”å›æ–°ç»“æœæ•°é‡"""
        count = 0
        while not self.pipeline.results_queue.empty():
            try:
                result = self.pipeline.results_queue.get_nowait()
                self.results.append(result)
                print_realtime_result(result, self.simulated_time)
                count += 1
            except Empty:
                break
        return count

    def _collect_all_results(self):
        """æ”¶é›†æ‰€æœ‰å‰©ä½™ç»“æœï¼Œè¿”å›æ”¶é›†æ•°é‡"""
        count = 0
        while not self.pipeline.results_queue.empty():
            try:
                result = self.pipeline.results_queue.get_nowait()
                self.results.append(result)
                count += 1
            except Empty:
                break
        return count

    def _collect_and_display_results(self):
        """æ”¶é›†å¹¶æ˜¾ç¤ºæ‰€æœ‰å‰©ä½™ç»“æœï¼Œè¿”å›æ”¶é›†æ•°é‡"""
        count = 0
        while not self.pipeline.results_queue.empty():
            try:
                result = self.pipeline.results_queue.get_nowait()
                self.results.append(result)
                print_realtime_result(result, self.simulated_time)
                count += 1
            except Empty:
                break
        return count


def main():
    parser = argparse.ArgumentParser(description="æµå¼å£°çº¹è¯†åˆ«æ¼”ç¤º")
    parser.add_argument("--mix-wav", required=True, help="æ··åˆéŸ³é¢‘æ–‡ä»¶")
    parser.add_argument("--target-wav", required=True, help="ç›®æ ‡è¯´è¯äººéŸ³é¢‘")
    parser.add_argument("--spk-embed-model", required=True, help="è¯´è¯äººåµŒå…¥æ¨¡å‹")
    parser.add_argument("--sense-voice", required=True, help="ASRæ¨¡å‹")
    parser.add_argument("--tokens", required=True, help="tokensæ–‡ä»¶")
    parser.add_argument("--provider", default="cuda", help="æ¨ç†è®¾å¤‡")
    parser.add_argument("--sv-threshold", type=float, default=0.4, help="SVé˜ˆå€¼")
    parser.add_argument("--chunk-size", type=int, default=1024, help="éŸ³é¢‘å—å¤§å°")
    parser.add_argument(
        "--process-seconds", type=float, default=3.0, help="æ¯æ¬¡å¤„ç†çš„ç§’æ•°"
    )
    parser.add_argument(
        "--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¢«è¿‡æ»¤çš„ç»“æœ"
    )
    parser.add_argument(
        "--vad-model", default="", help="VAD æ¨¡å‹è·¯å¾„ï¼ˆå¯ç”¨ VAD åˆ†æ®µæ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--vad-min-silence", type=float, default=0.25, help="VAD æœ€å°é™éŸ³æ—¶é•¿"
    )
    parser.add_argument(
        "--vad-min-speech", type=float, default=0.25, help="VAD æœ€å°è¯­éŸ³æ—¶é•¿"
    )
    parser.add_argument(
        "--max-segment-duration",
        type=float,
        default=3.0,
        help="VAD æ¨¡å¼ä¸‹æœ€å¤§åˆ†æ®µæ—¶é•¿ï¼ˆç§’ï¼‰",
    )
    args = parser.parse_args()

    # åˆ›å»ºå‚æ•°å¯¹è±¡
    class Args:
        pass

    pipeline_args = Args()
    pipeline_args.spk_embed_model = args.spk_embed_model
    pipeline_args.sense_voice = args.sense_voice
    pipeline_args.tokens = args.tokens
    pipeline_args.provider = args.provider
    pipeline_args.sv_threshold = args.sv_threshold
    pipeline_args.paraformer = ""
    pipeline_args.encoder = ""
    pipeline_args.decoder = ""
    pipeline_args.joiner = ""
    pipeline_args.decoding_method = "greedy_search"
    pipeline_args.feature_dim = 80
    pipeline_args.language = "auto"
    pipeline_args.num_threads = 2
    pipeline_args.osd_backend = "pyannote"
    pipeline_args.sep_backend = "asteroid"
    pipeline_args.sep_checkpoint = ""
    pipeline_args.osd_thr = 0.5
    pipeline_args.osd_win = 0.5
    pipeline_args.osd_hop = 0.25
    pipeline_args.min_overlap_dur = 0.2
    pipeline_args.sample_rate = 16000
    pipeline_args.chunk_size = args.chunk_size
    pipeline_args.process_seconds = args.process_seconds
    # VAD ç›¸å…³å‚æ•°
    pipeline_args.vad_model = args.vad_model
    pipeline_args.vad_min_silence = args.vad_min_silence
    pipeline_args.vad_min_speech = args.vad_min_speech
    pipeline_args.max_segment_duration = args.max_segment_duration

    # åˆ¤æ–­ä½¿ç”¨å“ªç§æ¨¡å¼
    use_vad_mode = bool(args.vad_model)

    print()
    print("â•”" + "â•" * 68 + "â•—")
    print("â•‘       ğŸ¤ å¤šè¯´è¯äººé‡å è¯­éŸ³åˆ†ç¦»ä¸è¯†åˆ«ç³»ç»Ÿ - æµå¼æ¼”ç¤º              â•‘")
    print("â•š" + "â•" * 68 + "â•")
    print()

    # è·å–éŸ³é¢‘ä¿¡æ¯
    mix_path = Path(args.mix_wav)
    target_path = Path(args.target_wav)

    info = torchaudio.info(str(mix_path))
    duration = info.num_frames / info.sample_rate

    mode_str = "VAD åˆ†æ®µæ¨¡å¼" if use_vad_mode else "å›ºå®šé—´éš”æ¨¡å¼"
    print_box(
        "ğŸ“Š æ¼”ç¤ºä¿¡æ¯",
        [
            f"æ··åˆéŸ³é¢‘: {mix_path.name}",
            f"éŸ³é¢‘æ—¶é•¿: {duration:.2f} ç§’",
            f"ç›®æ ‡è¯´è¯äºº: {target_path.name}",
            f"å¤„ç†æ¨¡å¼: {mode_str}",
            f"æµå¼å—å¤§å°: {args.chunk_size} samples",
        ]
        + ([f"å¤„ç†é—´éš”: {args.process_seconds} ç§’"] if not use_vad_mode else []),
    )
    print()

    if use_vad_mode:
        print_box(
            "ğŸ”§ æµå¼å¤„ç†æµç¨‹ (VAD ç‰ˆ)",
            [
                "1. éŸ³é¢‘åˆ†å—è¾“å…¥ (æ¨¡æ‹Ÿéº¦å…‹é£)",
                "2. VAD è¯­éŸ³æ£€æµ‹ (Silero VAD)",
                "3. 3æºåˆ†ç¦» (Conv-TasNet)",
                "4. è¯´è¯äººéªŒè¯ (3DSpeaker)",
                "5. è¯­éŸ³è¯†åˆ« (SenseVoice)",
                "â€» åŸºäºè¯­éŸ³è¾¹ç•Œåˆ†æ®µï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§",
            ],
        )
    else:
        print_box(
            "ğŸ”§ æµå¼å¤„ç†æµç¨‹ (ä¼˜åŒ–ç‰ˆ)",
            [
                "1. éŸ³é¢‘åˆ†å—è¾“å…¥ (æ¨¡æ‹Ÿéº¦å…‹é£)",
                "2. 3æºç›´æ¥åˆ†ç¦» (Conv-TasNet)",
                "3. è¯´è¯äººéªŒè¯ (3DSpeaker)",
                "4. è¯­éŸ³è¯†åˆ« (SenseVoice)",
                "5. å®æ—¶è¾“å‡ºåŒ¹é…ç»“æœ",
                "â€» æ— OSDä¾èµ–ï¼Œé¿å…çº§è”å¤±è´¥",
            ],
        )
    print()

    print("â³ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    start_time = time.time()

    import warnings

    warnings.filterwarnings("ignore")

    # æ ¹æ®æ¨¡å¼é€‰æ‹© pipeline
    if use_vad_mode:
        from vad_streaming_overlap3_core import VADStreamingOverlap3Pipeline

        pipeline = VADStreamingOverlap3Pipeline(pipeline_args, str(target_path))
    else:
        from optimized_streaming_overlap3_core import OptimizedStreamingOverlap3Pipeline

        pipeline = OptimizedStreamingOverlap3Pipeline(pipeline_args, str(target_path))

    load_time = time.time() - start_time
    print(f"âœ“ æ¨¡å‹åŠ è½½å®Œæˆ ({load_time:.2f}s)")
    print()

    # æ˜¾ç¤ºç›®æ ‡è¯´è¯äººä¿¡æ¯
    print_box(
        "ğŸ¯ ç›®æ ‡è¯´è¯äºº",
        [
            f"æ–‡ä»¶: {target_path.name}",
            f"åŸæ–‡: {pipeline.target_src_text[:60]}{'...' if len(pipeline.target_src_text) > 60 else ''}",
        ],
    )
    print()

    # åŠ è½½æ··åˆéŸ³é¢‘
    audio_data, file_sr = torchaudio.load(str(mix_path))
    if audio_data.shape[0] > 1:
        audio_data = audio_data.mean(dim=0)
    else:
        audio_data = audio_data.squeeze(0)

    if file_sr != 16000:
        audio_data = torchaudio.functional.resample(audio_data, file_sr, 16000)

    audio_np = audio_data.numpy()

    # åˆ›å»ºæµå¼æ¨¡æ‹Ÿå™¨å¹¶è¿è¡Œ
    simulator = StreamingSimulator(
        pipeline=pipeline,
        audio_data=audio_np,
        sample_rate=16000,
        chunk_size=args.chunk_size,
        process_seconds=args.process_seconds,
    )

    process_time = simulator.run(realtime_display=True)

    # è¿‡æ»¤åŒ¹é…çš„ç»“æœ
    matched_results = [
        r for r in simulator.results if r.get("sv_score", 0) >= args.sv_threshold
    ]

    # è°ƒè¯•æ¨¡å¼ï¼šæ˜¾ç¤ºè¢«è¿‡æ»¤çš„ç»“æœ
    if args.debug:
        filtered_results = [
            r for r in simulator.results if r.get("sv_score", 0) < args.sv_threshold
        ]
        if filtered_results:
            print("â•”" + "â•" * 68 + "â•—")
            print(
                "â•‘              ğŸ” è°ƒè¯•ä¿¡æ¯ - è¢«è¿‡æ»¤çš„ç»“æœï¼ˆSVåˆ†æ•°è¿‡ä½ï¼‰              â•‘"
            )
            print("â•š" + "â•" * 68 + "â•")
            print()
            for r in filtered_results:
                sv_score = r.get("sv_score", 0)
                text = r.get("text", "")
                stream_id = r.get("stream", "?")
                print(
                    f"  [åˆ†ç¦»#{stream_id}] SV={sv_score:.3f} (é˜ˆå€¼: {args.sv_threshold}) "
                    f"â†’ ğŸ“ {text[:50]}{'...' if len(text) > 50 else ''}"
                )
            print()

    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    print("â•”" + "â•" * 68 + "â•—")
    print("â•‘                       ğŸ“ˆ å¤„ç†ç»Ÿè®¡                               â•‘")
    print("â•š" + "â•" * 68 + "â•")
    print()

    rtf = process_time / duration if duration > 0 else 0
    sv_scores = [r.get("sv_score", 0) for r in matched_results if r.get("sv_score")]
    avg_sv = np.mean(sv_scores) if sv_scores else 0
    max_sv = max(sv_scores) if sv_scores else 0

    # æŒ‰ç±»å‹ç»Ÿè®¡
    kind_counts = {}
    for r in matched_results:
        k = r.get("kind", "unknown")
        kind_counts[k] = kind_counts.get(k, 0) + 1

    stats_lines = [
        f"æ€»è¯†åˆ«åˆ†æ®µ: {len(matched_results)}",
        f"å¤„ç†è€—æ—¶: {process_time:.2f} ç§’",
        f"éŸ³é¢‘æ—¶é•¿: {duration:.2f} ç§’",
        f"RTF: {rtf:.3f}x ({1/rtf:.1f}x å®æ—¶é€Ÿåº¦)" if rtf > 0 else "RTF: N/A",
        "",
        f"å¹³å‡ SV åˆ†æ•°: {avg_sv:.3f}",
        f"æœ€é«˜ SV åˆ†æ•°: {max_sv:.3f}",
    ]

    # è°ƒè¯•æ¨¡å¼ï¼šæ˜¾ç¤ºè¿‡æ»¤ç»Ÿè®¡
    total_results = len(simulator.results)
    filtered_count = total_results - len(matched_results)
    if args.debug and filtered_count > 0:
        stats_lines.insert(
            5,
            f"è¢«è¿‡æ»¤åˆ†æ®µ: {filtered_count} (SVåˆ†æ•° < {args.sv_threshold})",
        )

    for k, v in kind_counts.items():
        if k == "vad_separated":
            stats_lines.append(f"VADåˆ†ç¦»åˆ†æ®µ: {v}")
        elif k == "separated":
            stats_lines.append(f"åˆ†ç¦»åŒ¹é…åˆ†æ®µ: {v}")
        elif k == "clean":
            stats_lines.append(f"æ— é‡å åˆ†æ®µ: {v}")
        elif k == "overlap":
            stats_lines.append(f"OSDæ£€æµ‹åˆ†æ®µ: {v}")
        elif k == "full_separation":
            stats_lines.append(f"å…¨åˆ†ç¦»åˆ†æ®µ: {v}")

    for line in stats_lines:
        print(f"  {line}")
    print()

    # æ˜¾ç¤ºå®Œæ•´è¯†åˆ«æ–‡æœ¬æ‹¼æ¥
    if matched_results:
        # æŒ‰åºåˆ—å·æ’åºï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼Œç„¶åæŒ‰æ—¶é—´æ’åº
        sorted_results = sorted(
            matched_results, key=lambda r: (r.get("seq_id", 0), r.get("start", 0))
        )

        # ç›´æ¥æ‹¼æ¥æ–‡æœ¬ï¼ˆä¸ä½¿ç”¨åå¤„ç†å™¨ï¼‰
        full_text = "".join([r.get("text", "") for r in sorted_results])

        print("â•”" + "â•" * 68 + "â•—")
        print("â•‘                    ğŸ“„ å®Œæ•´è¯†åˆ«æ–‡æœ¬                             â•‘")
        print("â•š" + "â•" * 68 + "â•")
        print()

        # å¤„ç†é•¿æ–‡æœ¬çš„æ¢è¡Œæ˜¾ç¤º
        max_width = 66
        if len(full_text) <= max_width:
            print(f"  {full_text}")
        else:
            # æŒ‰å­—ç¬¦åˆ†è¡Œæ˜¾ç¤º
            for i in range(0, len(full_text), max_width):
                chunk = full_text[i : i + max_width]
                print(f"  {chunk}")
        print()

        # å¦‚æœå¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºç›®æ ‡æ–‡æœ¬å¯¹æ¯”
        if args.debug:
            print("â•”" + "â•" * 68 + "â•—")
            print("â•‘                  ğŸ“Š æ–‡æœ¬å¯¹æ¯”åˆ†æ                             â•‘")
            print("â•š" + "â•" * 68 + "â•")
            print()
            print(f"  ğŸ¯ ç›®æ ‡: {pipeline.target_src_text}")
            print(f"  ğŸ” è¯†åˆ«: {full_text}")
            print()
    else:
        print("â•”" + "â•" * 68 + "â•—")
        print("â•‘                    ğŸ“„ å®Œæ•´è¯†åˆ«æ–‡æœ¬                             â•‘")
        print("â•š" + "â•" * 68 + "â•")
        print()
        print("  ï¼ˆæ— åŒ¹é…ç»“æœï¼‰")
        print()

    print("â•”" + "â•" * 68 + "â•—")
    print("â•‘                      âœ… æµå¼æ¼”ç¤ºå®Œæˆï¼                          â•‘")
    print("â•š" + "â•" * 68 + "â•")
    print()


if __name__ == "__main__":
    main()
